{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on site_code_dx 0 of 153 (C4001)\n",
      "on site_code_dx 1 of 153 (C4023)\n",
      "on site_code_dx 2 of 153 (C1026)\n",
      "on site_code_dx 3 of 153 (C1010)\n",
      "on site_code_dx 4 of 153 (C1066)\n",
      "on site_code_dx 5 of 153 (C1011)\n",
      "on site_code_dx 6 of 153 (C1080)\n",
      "on site_code_dx 7 of 153 (C1063)\n",
      "on site_code_dx 8 of 153 (C1008)\n",
      "on site_code_dx 9 of 153 (C1679)\n",
      "on site_code_dx 10 of 153 (C1082)\n",
      "on site_code_dx 11 of 153 (C1054)\n",
      "on site_code_dx 12 of 153 (C1413)\n",
      "on site_code_dx 13 of 153 (C1106)\n",
      "on site_code_dx 14 of 153 (C1051)\n",
      "on site_code_dx 15 of 153 (C1059)\n",
      "on site_code_dx 16 of 153 (C1062)\n",
      "on site_code_dx 17 of 153 (C1034)\n",
      "on site_code_dx 18 of 153 (C1681)\n",
      "on site_code_dx 19 of 153 (C1014)\n",
      "on site_code_dx 20 of 153 (C4037)\n",
      "on site_code_dx 21 of 153 (C1004)\n",
      "on site_code_dx 22 of 153 (C4014)\n",
      "on site_code_dx 23 of 153 (C4015)\n",
      "on site_code_dx 24 of 153 (C4061)\n",
      "on site_code_dx 25 of 153 (C4038)\n",
      "on site_code_dx 26 of 153 (C1083)\n",
      "on site_code_dx 27 of 153 (C1093)\n",
      "on site_code_dx 28 of 153 (C1084)\n",
      "on site_code_dx 29 of 153 (C5015)\n",
      "on site_code_dx 30 of 153 (C2047)\n",
      "on site_code_dx 31 of 153 (C4056)\n",
      "on site_code_dx 32 of 153 (C5016)\n",
      "on site_code_dx 33 of 153 (C5017)\n",
      "on site_code_dx 34 of 153 (C2049)\n",
      "on site_code_dx 35 of 153 (C4002)\n",
      "on site_code_dx 36 of 153 (C4016)\n",
      "on site_code_dx 37 of 153 (C4054)\n",
      "on site_code_dx 38 of 153 (C4017)\n",
      "on site_code_dx 39 of 153 (C2011)\n",
      "on site_code_dx 40 of 153 (C2002)\n",
      "on site_code_dx 41 of 153 (C2010)\n",
      "on site_code_dx 42 of 153 (C4018)\n",
      "on site_code_dx 43 of 153 (C3010)\n",
      "on site_code_dx 44 of 153 (C3014)\n",
      "on site_code_dx 45 of 153 (C3015)\n",
      "on site_code_dx 46 of 153 (C1029)\n",
      "on site_code_dx 47 of 153 (C1086)\n",
      "on site_code_dx 48 of 153 (C1056)\n",
      "on site_code_dx 49 of 153 (C1055)\n",
      "on site_code_dx 50 of 153 (C1399)\n",
      "on site_code_dx 51 of 153 (C1018)\n",
      "on site_code_dx 52 of 153 (C1144)\n",
      "on site_code_dx 53 of 153 (C1745)\n",
      "on site_code_dx 54 of 153 (C3011)\n",
      "on site_code_dx 55 of 153 (C1088)\n",
      "on site_code_dx 56 of 153 (C2003)\n",
      "on site_code_dx 57 of 153 (C5060)\n",
      "on site_code_dx 58 of 153 (C5018)\n",
      "on site_code_dx 59 of 153 (C4024)\n",
      "on site_code_dx 60 of 153 (C4019)\n",
      "on site_code_dx 61 of 153 (C2051)\n",
      "on site_code_dx 62 of 153 (C2004)\n",
      "on site_code_dx 63 of 153 (C2016)\n",
      "on site_code_dx 64 of 153 (C2005)\n",
      "on site_code_dx 65 of 153 (C5019)\n",
      "on site_code_dx 66 of 153 (C3012)\n",
      "on site_code_dx 67 of 153 (C1089)\n",
      "on site_code_dx 68 of 153 (C2006)\n",
      "on site_code_dx 69 of 153 (C2053)\n",
      "on site_code_dx 70 of 153 (C2017)\n",
      "on site_code_dx 71 of 153 (C2194)\n",
      "on site_code_dx 72 of 153 (C1087)\n",
      "on site_code_dx 73 of 153 (C1090)\n",
      "on site_code_dx 74 of 153 (C1091)\n",
      "on site_code_dx 75 of 153 (C2131)\n",
      "on site_code_dx 76 of 153 (C5002)\n",
      "on site_code_dx 77 of 153 (C2055)\n",
      "on site_code_dx 78 of 153 (C2056)\n",
      "on site_code_dx 79 of 153 (C2061)\n",
      "on site_code_dx 80 of 153 (C1092)\n",
      "on site_code_dx 81 of 153 (C3013)\n",
      "on site_code_dx 82 of 153 (C3018)\n",
      "on site_code_dx 83 of 153 (C2127)\n",
      "on site_code_dx 84 of 153 (C3043)\n",
      "on site_code_dx 85 of 153 (C3016)\n",
      "on site_code_dx 86 of 153 (C5076)\n",
      "on site_code_dx 87 of 153 (C5020)\n",
      "on site_code_dx 88 of 153 (C1015)\n",
      "on site_code_dx 89 of 153 (C1030)\n",
      "on site_code_dx 90 of 153 (C1024)\n",
      "on site_code_dx 91 of 153 (C1058)\n",
      "on site_code_dx 92 of 153 (C1069)\n",
      "on site_code_dx 93 of 153 (C1035)\n",
      "on site_code_dx 94 of 153 (C1027)\n",
      "on site_code_dx 95 of 153 (C1101)\n",
      "on site_code_dx 96 of 153 (C1094)\n",
      "on site_code_dx 97 of 153 (C2059)\n",
      "on site_code_dx 98 of 153 (C4022)\n",
      "on site_code_dx 99 of 153 (C5001)\n",
      "on site_code_dx 100 of 153 (C3017)\n",
      "on site_code_dx 101 of 153 (C5066)\n",
      "on site_code_dx 102 of 153 (C4003)\n",
      "on site_code_dx 103 of 153 (C3019)\n",
      "on site_code_dx 104 of 153 (C3022)\n",
      "on site_code_dx 105 of 153 (C5063)\n",
      "on site_code_dx 106 of 153 (C5003)\n",
      "on site_code_dx 107 of 153 (C3020)\n",
      "on site_code_dx 108 of 153 (C3001)\n",
      "on site_code_dx 109 of 153 (C2060)\n",
      "on site_code_dx 110 of 153 (C4025)\n",
      "on site_code_dx 111 of 153 (C2062)\n",
      "on site_code_dx 112 of 153 (C2007)\n",
      "on site_code_dx 113 of 153 (C2214)\n",
      "on site_code_dx 114 of 153 (C1095)\n",
      "on site_code_dx 115 of 153 (C2041)\n",
      "on site_code_dx 116 of 153 (C2008)\n",
      "on site_code_dx 117 of 153 (C1098)\n",
      "on site_code_dx 118 of 153 (C2063)\n",
      "on site_code_dx 119 of 153 (C1411)\n",
      "on site_code_dx 120 of 153 (C2064)\n",
      "on site_code_dx 121 of 153 (C2015)\n",
      "on site_code_dx 122 of 153 (C2050)\n",
      "on site_code_dx 123 of 153 (C2066)\n",
      "on site_code_dx 124 of 153 (C4026)\n",
      "on site_code_dx 125 of 153 (C4021)\n",
      "on site_code_dx 126 of 153 (C2168)\n",
      "on site_code_dx 127 of 153 (C4020)\n",
      "on site_code_dx 128 of 153 (C3023)\n",
      "on site_code_dx 129 of 153 (C2065)\n",
      "on site_code_dx 130 of 153 (C1009)\n",
      "on site_code_dx 131 of 153 (C1112)\n",
      "on site_code_dx 132 of 153 (C2068)\n",
      "on site_code_dx 133 of 153 (C5004)\n",
      "on site_code_dx 134 of 153 (C5021)\n",
      "on site_code_dx 135 of 153 (C2069)\n",
      "on site_code_dx 136 of 153 (C2052)\n",
      "on site_code_dx 137 of 153 (C2057)\n",
      "on site_code_dx 138 of 153 (C1072)\n",
      "on site_code_dx 139 of 153 (C1061)\n",
      "on site_code_dx 140 of 153 (C2070)\n",
      "on site_code_dx 141 of 153 (C2009)\n",
      "on site_code_dx 142 of 153 (C1017)\n",
      "on site_code_dx 143 of 153 (C1070)\n",
      "on site_code_dx 144 of 153 (C1073)\n",
      "on site_code_dx 145 of 153 (C1078)\n",
      "on site_code_dx 146 of 153 (C1077)\n",
      "on site_code_dx 147 of 153 (C1028)\n",
      "on site_code_dx 148 of 153 (C1007)\n",
      "on site_code_dx 149 of 153 (C1074)\n",
      "on site_code_dx 150 of 153 (C1067)\n",
      "on site_code_dx 151 of 153 (C1099)\n",
      "on site_code_dx 152 of 153 (C5006)\n",
      "on site_code_dx 153 of 153 (C2071)\n",
      "Overall MASE for ARIMA predictions: 1.2208674230470997\n",
      "Overall MASE for Naive predictions: 1.9333534523888092\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@authors: anbarry, Eddie Kunkel\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from pdb import set_trace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PRINT_VERBOSE = False\n",
    "\n",
    "def MASE(training_series, testing_series, prediction_series):\n",
    "    \"\"\"\n",
    "    Computes the mean-absolute scaled error forcast error for univariate time series prediction.\n",
    "    \n",
    "    See \"Another look at measures of forecast accuracy\", Rob J Hyndman\n",
    "    \n",
    "    parameters:\n",
    "        training_series: the series used to train the model, 1d numpy array\n",
    "        testing_series: the test series to predict, 1d numpy array or float\n",
    "        prediction_series: the prediction of testing_series, 1d numpy array (same size as testing_series) or float\n",
    "        absolute: \"squares\" to use sum of squares and root the result, \"absolute\" to use absolute values.\n",
    "    \n",
    "    \"\"\"\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum()/(n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series )\n",
    "    return errors.mean()/d\n",
    "\n",
    "### import data and adjust to only necessary cols\n",
    "full_df = pd.read_csv(r'../data/ProcessingOutput/contraceptive_logistics_data_clean.csv')\n",
    "full_df['date'] = pd.to_datetime(full_df['date'], format=\"%Y-%m-%d\")\n",
    "full_df = full_df[[\n",
    "    'site_code',\n",
    "    'product_code',\n",
    "    'stock_distributed',\n",
    "    'date'\n",
    "    ]]\n",
    "\n",
    "full_df['year'] = full_df['date'].dt.year\n",
    "full_df['month'] = full_df['date'].dt.month\n",
    "full_df['day'] = full_df['date'].dt.dayofyear\n",
    "full_df['weekday'] = full_df['date'].dt.weekday\n",
    "full_df = full_df.set_index('date', drop = False)\n",
    "full_df.index.names = ['date_index']\n",
    "full_df = full_df[['site_code','product_code','stock_distributed']]\n",
    "\n",
    "AR = [0,1,3,6]\n",
    "I=[0,1]\n",
    "MA= [0,1,3,6]\n",
    "\n",
    "# !#EPK DEBUG PARAMS\n",
    "# AR = [3,6]\n",
    "# I=[0,1]\n",
    "# MA= [3,6]\n",
    "\n",
    "a = [AR,I,MA]\n",
    "arima_params_combinations = list(product(*a))\n",
    "\n",
    "unique_site_codes = full_df['site_code'].unique()\n",
    "unique_product_codes = full_df['product_code'].unique()\n",
    "\n",
    "# !#EPK DEBUG Code to randomly sample some of the site codes for testing\n",
    "# unique_site_codes = np.random.choice(unique_site_codes, 10, replace=False)\n",
    "# unique_product_codes = np.random.choice(unique_product_codes, 10, replace=False)\n",
    "\n",
    "# Record MASE and model parameters. Will be used for model selection\n",
    "eval_df_list = []\n",
    "\n",
    "# List of dataframe which each contain every date for a respective site/product code combination\n",
    "combo_df_list = []\n",
    "\n",
    "for site_code_dx, site_code in enumerate(unique_site_codes):\n",
    "    t0 = time.time()\n",
    "    print('on site_code_dx {} of {} ({})'.format(site_code_dx, len(unique_site_codes)-1, site_code))\n",
    "\n",
    "    for product_code_dx, product_code in enumerate(unique_product_codes):\n",
    "        product_code_start_time = time.time()\n",
    "        if PRINT_VERBOSE:\n",
    "            print('on product_code_dx {} of {} ({})'.format(product_code_dx, len(unique_product_codes)-1, product_code))\n",
    "\n",
    "        # Select the current site/product code combination and fill in missing dates\n",
    "        all_dates = pd.date_range(start=datetime(2016,1,1), end=datetime(2019,9,1), freq='MS')\n",
    "\n",
    "        current_df = full_df[(full_df['product_code']==product_code) & (full_df['site_code']==site_code)]\n",
    "        current_df = current_df.reindex(all_dates, fill_value=None)\n",
    "        current_df.loc[:,'site_code'] = site_code\n",
    "        current_df.loc[:,'product_code'] = product_code\n",
    "        current_df.index.names = ['date_index']\n",
    "\n",
    "        # Ensure all NaNs are set to np.nan to play nice with StatsModels\n",
    "        current_df.loc[:,'stock_distributed'] = current_df['stock_distributed'].fillna(np.nan)\n",
    "\n",
    "        train_df_p = current_df[current_df.index < '2019-07-01']\n",
    "        test_df_p = current_df[current_df.index > '2019-06-01']\n",
    "\n",
    "        # Calculate the naive solution by averaging the 3 most recent months\n",
    "        test_df_p['naive_pred'] = train_df_p[~train_df_p['stock_distributed'].isna()]['stock_distributed'].tail(3).mean()\n",
    "        naive_MASE = MASE(train_df_p['stock_distributed'].fillna(0), test_df_p['stock_distributed'].fillna(0), test_df_p['naive_pred'].fillna(0))\n",
    "\n",
    "        best_ARIMA_MASE = None\n",
    "        best_ARIMA_pred = None\n",
    "        best_ARIMA_params = None\n",
    "        \n",
    "        # INSERT ADDITIONAL RULES FOR WHEN NAIVE MODEL SHOULD BE USED, REGARDLESS OF OTHER METRICS\n",
    "        num_non_nan_train_dates = (~train_df_p['stock_distributed'].isna()).sum()\n",
    "\n",
    "        if num_non_nan_train_dates > 5:\n",
    "            for arima_params in arima_params_combinations:\n",
    "                if PRINT_VERBOSE:\n",
    "                    print('fitting ARIMA model using params {}'.format(arima_params))\n",
    "\n",
    "                try:\n",
    "                    arima_model = ARIMA(train_df_p.stock_distributed, order=arima_params).fit()\n",
    "\n",
    "                    arima_pred = arima_model.predict(start=datetime(2019,7,1), end=datetime(2019,9,1))\n",
    "                    model_MASE = MASE(train_df_p['stock_distributed'].fillna(0), test_df_p['stock_distributed'].fillna(0), arima_pred)\n",
    "\n",
    "                    # Store the parameters of the best-performing ARIMA model\n",
    "                    if (not best_ARIMA_MASE) or (model_MASE < best_ARIMA_MASE):\n",
    "                        best_ARIMA_MASE = model_MASE\n",
    "                        best_ARIMA_pred = arima_pred\n",
    "                        best_ARIMA_params = arima_params\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        curr_eval_df = pd.DataFrame({'site_code' : [site_code],\n",
    "                                     'product_code' : [product_code],\n",
    "                                     'ARIMA_params' : [best_ARIMA_params],\n",
    "                                     'ARIMA_MASE' : [best_ARIMA_MASE],\n",
    "                                     'naive_MASE' : [naive_MASE],\n",
    "                                     'num_non_nan_train_dates' : [num_non_nan_train_dates]})\n",
    "\n",
    "        eval_df_list.append(curr_eval_df)\n",
    "\n",
    "        test_df_p['ARIMA_pred'] = best_ARIMA_pred\n",
    "        test_df_p = test_df_p[['site_code','product_code','naive_pred','ARIMA_pred']]\n",
    "        current_df = pd.merge(current_df, test_df_p, how='outer', on=['date_index','site_code','product_code'])\n",
    "\n",
    "        # concatenating the individual site/product combination dataframes and doing a large merge later is\n",
    "        #     much faster than doing an outer merge every loop\n",
    "        combo_df_list.append(current_df)\n",
    "\n",
    "        if PRINT_VERBOSE:\n",
    "            print('execution of this site/product combination took {} seconds'.format(time.time()-product_code_start_time))\n",
    "\n",
    "\n",
    "# DF with data and predictions for all site/product codes run\n",
    "combo_df = pd.concat(combo_df_list)\n",
    "\n",
    "ARIMA_MASE = MASE(combo_df['stock_distributed'].fillna(0), combo_df['stock_distributed'], combo_df['ARIMA_pred'])\n",
    "print('Overall MASE for ARIMA predictions: {}'.format(ARIMA_MASE))\n",
    "\n",
    "Naive_MASE = MASE(combo_df['stock_distributed'].fillna(0), combo_df['stock_distributed'], combo_df['naive_pred'])\n",
    "print('Overall MASE for Naive predictions: {}'.format(Naive_MASE))\n",
    "\n",
    "eval_df = pd.concat(eval_df_list)\n",
    "eval_df['ARIMA_performed_better'] = eval_df['ARIMA_MASE'] < eval_df['naive_MASE']\n",
    "\n",
    "full_df = pd.merge(full_df, combo_df.drop(columns=['stock_distributed']), how='outer', on=['date_index','site_code','product_code'])\n",
    "full_df.to_csv('../predictions/full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n",
      "ARIMA model failed... Substituting with naive prediction\n"
     ]
    }
   ],
   "source": [
    "# Draft final predictions using the best performing model\n",
    "predictions_df_list = []\n",
    "prediction_dates = pd.date_range(start=datetime(2019,10,1), end=datetime(2019,12,1), freq='MS')\n",
    "USE_NAIVE_ONLY = False\n",
    "for site_code_dx, site_code in enumerate(unique_site_codes):\n",
    "    for product_code_dx, product_code in enumerate(unique_product_codes):\n",
    "        curr_df = full_df.loc[(full_df['site_code'] == site_code) & (full_df['product_code'] == product_code),:]\n",
    "        curr_df.sort_index(inplace=True)\n",
    "        curr_eval = eval_df.loc[(eval_df['site_code'] == site_code) & (eval_df['product_code'] == product_code),:]\n",
    "        curr_prediction = pd.DataFrame(index=prediction_dates)\n",
    "        curr_prediction['site_code'] = site_code\n",
    "        curr_prediction['product_code'] = product_code\n",
    "\n",
    "        # Naive model prediction\n",
    "        curr_naive_pred = curr_df[~curr_df['stock_distributed'].isna()]['stock_distributed'].tail(3).mean()\n",
    "        \n",
    "        if np.isnan(curr_naive_pred):\n",
    "            curr_naive_pred = 0\n",
    "\n",
    "        if USE_NAIVE_ONLY:\n",
    "            curr_prediction['predicted_value'] = curr_naive_pred\n",
    "            predictions_df_list.append(curr_prediction)\n",
    "            continue\n",
    "        \n",
    "        # ARIMA model prediction\n",
    "        if (curr_eval['ARIMA_performed_better'].iloc[0]) & (curr_eval['num_non_nan_train_dates'].iloc[0] > 0):\n",
    "            try:\n",
    "                arima_model = ARIMA(curr_df['stock_distributed'], order=curr_eval['ARIMA_params'].iloc[0]).fit()\n",
    "                arima_pred = arima_model.predict(start=datetime(2019,10,1), end=datetime(2019,12,1))\n",
    "                curr_prediction['predicted_value'] = arima_pred\n",
    "            except:\n",
    "                print('ARIMA model failed... Substituting with naive prediction')\n",
    "                # Use naive model if ARIMA fails to train\n",
    "                curr_prediction['predicted_value'] = curr_naive_pred\n",
    "        else:\n",
    "            curr_prediction['predicted_value'] = curr_naive_pred\n",
    "\n",
    "        predictions_df_list.append(curr_prediction)\n",
    "\n",
    "predictions = pd.concat(predictions_df_list)\n",
    "predictions['year'] = predictions.index.year\n",
    "predictions['month'] = predictions.index.month\n",
    "predictions = predictions[['year','month','site_code','product_code','predicted_value']]\n",
    "if USE_NAIVE_ONLY:\n",
    "    predictions.to_csv('../predictions/NAIVE_predictions.csv', index=False)  \n",
    "else:\n",
    "    predictions.to_csv('../predictions/COMBINED_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USAID",
   "language": "python",
   "name": "usaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
